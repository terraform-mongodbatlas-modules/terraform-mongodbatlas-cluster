from __future__ import annotations

from pathlib import Path

import pytest
from tf_gen.cli import generate_for_config
from tf_gen.conftest import DEFAULT_PROVIDERS
from tf_gen.section import make_markers, update_section


@pytest.fixture
def cli_testdata_dir(testdata_dir: Path) -> Path:
    return testdata_dir / "cli"


def test_make_markers():
    begin, end = make_markers("gen.yaml", "project")
    assert (
        begin
        == "# START Code generated by `tf-gen --config gen.yaml --target project`. DO NOT EDIT."
    )
    assert (
        end
        == "# END Code generated by `tf-gen --config gen.yaml --target project`. DO NOT EDIT."
    )


def test_update_section_append():
    result = update_section("", "# BEGIN", "# END", "content")
    assert result == "# BEGIN\ncontent\n# END\n"


def test_update_section_replace():
    existing = "# BEGIN\nold\n# END\n"
    result = update_section(existing, "# BEGIN", "# END", "new")
    assert result == "# BEGIN\nnew\n# END\n"


def test_update_section_append_to_existing():
    existing = "# Manual content\n"
    result = update_section(existing, "# BEGIN", "# END", "generated")
    expected = "# Manual content\n\n# BEGIN\ngenerated\n# END\n"
    assert result == expected


def test_generate_for_config_project(cli_testdata_dir: Path, tmp_path: Path):
    config_path = cli_testdata_dir / "project_gen.yaml"
    results = generate_for_config(
        config_path,
        dest_path=tmp_path,
        dry_run=True,
        provider_defaults=DEFAULT_PROVIDERS,
        cache_dir=cli_testdata_dir,
    )
    assert len(results) == 3
    # Check files generated
    expected_files = {"variables_resource.tf", "main.tf", "outputs.tf"}
    actual_files = {Path(k).name for k in results}
    assert actual_files == expected_files
    # Check markers present
    for content in results.values():
        assert "# START Code generated by" in content
        assert "# END Code generated by" in content


def test_generate_for_config_target_filter(cli_testdata_dir: Path, tmp_path: Path):
    config_path = cli_testdata_dir / "multi_resource_gen.yaml"
    results = generate_for_config(
        config_path,
        target="project",
        dest_path=tmp_path,
        dry_run=True,
        provider_defaults=DEFAULT_PROVIDERS,
        cache_dir=cli_testdata_dir,
    )
    # Should only have project, not cloud_backup_schedule
    for content in results.values():
        assert "--target project" in content
        assert "--target cloud_backup_schedule" not in content


def test_generate_single_variable_mode(cli_testdata_dir: Path, tmp_path: Path):
    config_path = cli_testdata_dir / "single_variable_gen.yaml"
    results = generate_for_config(
        config_path,
        dest_path=tmp_path,
        dry_run=True,
        provider_defaults=DEFAULT_PROVIDERS,
        cache_dir=cli_testdata_dir,
    )
    # In single variable mode, there should be one object variable
    for filepath, content in results.items():
        if "variables" in filepath:
            assert 'variable "mongodbatlas_project"' in content


def test_generate_single_output_mode(cli_testdata_dir: Path, tmp_path: Path):
    config_path = cli_testdata_dir / "single_output_gen.yaml"
    results = generate_for_config(
        config_path,
        dest_path=tmp_path,
        dry_run=True,
        provider_defaults=DEFAULT_PROVIDERS,
        cache_dir=cli_testdata_dir,
    )
    for filepath, content in results.items():
        if "outputs" in filepath:
            assert 'output "project"' in content


def test_generate_resource_count_mode(cli_testdata_dir: Path, tmp_path: Path):
    """use_resource_count should generate length() guards in outputs."""
    config_path = cli_testdata_dir / "count_safe_outputs_gen.yaml"
    results = generate_for_config(
        config_path,
        dest_path=tmp_path,
        dry_run=True,
        provider_defaults=DEFAULT_PROVIDERS,
        cache_dir=cli_testdata_dir,
    )
    for filepath, content in results.items():
        if "outputs" in filepath:
            assert "length(" in content
        if "main" in filepath:
            # Resource should not have count meta-arg unless explicitly set
            assert "mongodbatlas_project" in content


def test_generate_no_schema_computability(cli_testdata_dir: Path, tmp_path: Path):
    """use_schema_computability=false makes all vars nullable with default=null."""
    config_path = cli_testdata_dir / "no_schema_computability_gen.yaml"
    results = generate_for_config(
        config_path,
        dest_path=tmp_path,
        dry_run=True,
        provider_defaults=DEFAULT_PROVIDERS,
        cache_dir=cli_testdata_dir,
    )
    for filepath, content in results.items():
        if "variables" in filepath:
            # Variables should have default = null for non-required attrs
            assert "default" in content
            # Required vars (name, org_id) should not have default
            # Check that we have some nullable variables
            assert "null" in content


def test_generate_single_output_with_count(cli_testdata_dir: Path, tmp_path: Path):
    """Combined use_single_output + use_resource_count generates guarded single output."""
    config_path = cli_testdata_dir / "single_output_with_count_gen.yaml"
    results = generate_for_config(
        config_path,
        dest_path=tmp_path,
        dry_run=True,
        provider_defaults=DEFAULT_PROVIDERS,
        cache_dir=cli_testdata_dir,
    )
    for filepath, content in results.items():
        if "outputs" in filepath:
            # Single output with count guard
            assert 'output "project"' in content
            assert "length(" in content
